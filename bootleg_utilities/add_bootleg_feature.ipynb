{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dfs/scratch1/simran/tutorial/bootleg-internal/.bootinternal/lib/python3.6/site-packages/pandas/compat/__init__.py:85: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n",
      "/dfs/scratch1/simran/tutorial/bootleg-internal/.bootinternal/lib/python3.6/site-packages/pandas/compat/__init__.py:85: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "import ujson\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "import csv\n",
    "from collections import defaultdict, OrderedDict\n",
    "import jsonlines\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mentions(file): \n",
    "    lines = []\n",
    "    with jsonlines.open(file) as f: \n",
    "        for line in f: \n",
    "            new_line = {\n",
    "                'id': line['id'],\n",
    "                'sentence': line['sentence'],\n",
    "                'aliases': line['aliases'], \n",
    "                'spans': line['spans'],\n",
    "                'gold': line['gold'],\n",
    "                'cand_probs': line['cand_probs'],\n",
    "                'qids': line['qids'],\n",
    "                'sent_idx_unq': line['sent_idx_unq'],\n",
    "                'probs': line['probs'],\n",
    "                'ctx_emb_ids': line['ctx_emb_ids'],\n",
    "                'entity_ids': line['entity_ids']\n",
    "            }\n",
    "            lines.append(new_line)\n",
    "    return pd.DataFrame(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load bootleg labels, mapping of labeled sentences to tacred ids, and tacred splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'sentence', 'aliases', 'spans', 'gold', 'cand_probs', 'qids',\n",
      "       'sent_idx_unq', 'probs', 'ctx_emb_ids', 'entity_ids'],\n",
      "      dtype='object')\n",
      "(106264, 11)\n"
     ]
    }
   ],
   "source": [
    "bootleg_directory = # FILL IN DIRECTORY OF BOOTLEG EMBS AND LABELS\n",
    "tacred_diretory = # FILL IN DIRECTORY OF TACRED DATA\n",
    "\n",
    "boot_labels_file = \"{}bootleg_labels.jsonl\".format(bootleg_directory)\n",
    "bootleg_labels_df = load_mentions(boot_labels_file)\n",
    "print(bootleg_labels_df.columns)\n",
    "print(bootleg_labels_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68124, 14)\n",
      "(22631, 14)\n",
      "(15509, 14)\n"
     ]
    }
   ],
   "source": [
    "train_file = \"{}/train.json\".format(base_data)\n",
    "with open(train_file) as train:\n",
    "    df_train = json.load(train)\n",
    "    df_train = pd.DataFrame.from_dict(df_train, orient='columns')\n",
    "    print(df_train.shape)\n",
    "    \n",
    "dev_file = \"{}/dev_rev.json\".format(base_data)\n",
    "with open(dev_file) as dev:\n",
    "    df_dev = json.load(dev)\n",
    "    df_dev = pd.DataFrame.from_dict(df_dev, orient='columns')\n",
    "    print(df_dev.shape)\n",
    "    \n",
    "test_file = \"{}/test_rev.json\".format(base_data)\n",
    "with open(test_file) as test:\n",
    "    df_test = json.load(test)\n",
    "    df_test = pd.DataFrame.from_dict(df_test, orient='columns')\n",
    "    print(df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain the ent_id features to be used in tacred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx_emb_id_dict = {}\n",
    "ctx_emb_id_dict_first = {}\n",
    "qid_dict = {}\n",
    "qid_dict_first = {}\n",
    "\n",
    "for ind, row in bootleg_labels_df.iterrows():\n",
    "    ctx_emb_ids = row['ctx_emb_ids']\n",
    "    qids = row['qids']\n",
    "    spans = row['spans']\n",
    "    \n",
    "    # get sentence length\n",
    "    example = row['sentence']\n",
    "    tokens = example.split(' ')\n",
    "    length = len(tokens)\n",
    "    \n",
    "    # initialize result datastructures\n",
    "    ctx_emb_id_result = [-1] * length\n",
    "    qid_result = ['UNK'] * length\n",
    "    \n",
    "    ctx_emb_id_result_first = [-1] * length\n",
    "    qid_result_first = ['UNK'] * length\n",
    "    \n",
    "    for i in range(len(spans)):\n",
    "        span = spans[i]\n",
    "        start, end = span[0], span[1]\n",
    "        span_len = end-start\n",
    "        \n",
    "        # contextual\n",
    "        ctx_emb_id = ctx_emb_ids[i]\n",
    "        ctx_emb_id_lst = [ctx_emb_id] * span_len\n",
    "        ctx_emb_id_result[start:end] = ctx_emb_id_lst\n",
    "        ctx_emb_id_result_first[start] = ctx_emb_id \n",
    "         \n",
    "        # qids\n",
    "        qid = qids[i]\n",
    "        qid_lst = [qid] * span_len\n",
    "        qid_result[start:end] = qid_lst\n",
    "        qid_result_first[start] = qid\n",
    "        \n",
    "    idx = row['id']\n",
    "    if idx in ctx_emb_id_dict:\n",
    "        raise ValueError('duplicate indices!')\n",
    "    \n",
    "    ctx_emb_id_dict[idx] = ctx_emb_id_result\n",
    "    qid_dict[idx] = qid_result\n",
    "    \n",
    "    ctx_emb_id_dict_first[idx] = ctx_emb_id_result_first\n",
    "    qid_dict_first[idx] = qid_result_first\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add the features to the tacred data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfs = [df_train, df_dev, df_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for df in dfs:\n",
    "    df[\"entity_emb_id\"] = np.nan\n",
    "    df['entity_emb_id_first'] = np.nan\n",
    "    df['ent_id'] = np.nan\n",
    "    df['ent_id_first'] = np.nan\n",
    "\n",
    "    dict_ctx_emb_id = {}\n",
    "    dict_ctx_emb_id_first = {}\n",
    "    dict_qid = {}\n",
    "    dict_qid_first = {}\n",
    "\n",
    "    for ind, row in df.iterrows():\n",
    "        idx = row['id']\n",
    "        tokens = row['token']\n",
    "        length = len(tokens)\n",
    "\n",
    "        # initialize result datastructures\n",
    "        ctx_emb_id_default = [-1] * length\n",
    "        qid_default = ['UNK'] * length\n",
    "\n",
    "        # contextual\n",
    "        if idx in ctx_emb_id_dict:\n",
    "            dict_ctx_emb_id[idx] =  ctx_emb_id_dict[idx]\n",
    "        else:\n",
    "            dict_ctx_emb_id[idx] = ctx_emb_id_default\n",
    "\n",
    "        if idx in ctx_emb_id_dict_first:\n",
    "            dict_ctx_emb_id_first[idx] = ctx_emb_id_dict_first[idx]\n",
    "        else:\n",
    "            dict_ctx_emb_id_first[idx] = ctx_emb_id_default\n",
    "\n",
    "        # qids\n",
    "        if idx in qid_dict:\n",
    "            dict_qid[idx] = qid_dict[idx]\n",
    "        else:\n",
    "            dict_qid[idx] = qid_default\n",
    "\n",
    "        if idx in qid_dict_first:\n",
    "            dict_qid_first[idx] = qid_dict_first[idx]\n",
    "        else:\n",
    "            dict_qid_first[idx] = qid_default\n",
    "        \n",
    "    assert len(dict_ctx_emb_id.keys()) == df.shape[0], print(len(dict_ctx_emb_id.keys()), df.shape[0])\n",
    "    assert len(dict_ctx_emb_id_first.keys()) == df.shape[0], print(len(dict_ctx_emb_id_first.keys()), df.shape[0])\n",
    "    assert len(dict_qid.keys()) == df.shape[0], print(len(dict_qid.keys()), df.shape[0])\n",
    "    assert len(dict_qid_first.keys()) == df.shape[0], print(len(dict_qid_first.keys()), df.shape[0])\n",
    "    df['entity_emb_id'] = df['id'].map(dict_ctx_emb_id)\n",
    "    df['entity_emb_id_first'] = df['id'].map(dict_ctx_emb_id_first)\n",
    "    df['ent_id'] = df['id'].map(dict_qid)\n",
    "    df['ent_id_first'] = df['id'].map(dict_qid_first)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the tacred data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/dfs/scratch1/simran/tacred/tacred-relation-bootleg/dataset_bootleg_iclr_model/bootleg_092620/basic_full_sentences//filt_1015_v1\n"
     ]
    }
   ],
   "source": [
    "out_dir = os.path.dirname('{}/'.format(bootleg_directory))\n",
    "print(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_out = df_train.to_json(r'{}/train_ent.json'.format(out_dir),orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_out = df_dev.to_json(r'{}/dev_rev_ent.json'.format(out_dir),orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_out = df_test.to_json(r'{}/test_rev_ent.json'.format(out_dir),orient='records')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
